<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.66.0" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
  <link rel="stylesheet" href="../css/normalize.css">
  <link rel="stylesheet" href="../css/skeleton.css">
  <link rel="stylesheet" href="../css/custom.css">
  <link rel="alternate" href="index.xml" type="application/rss+xml" title="Speech Research">
  <link rel="shortcut icon" href="favicon.png" type="image/x-icon" />
  <title>GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework</title>
</head>

<body>

  <div class="container">

    <header role="banner">

    </header>


    <main role="main">
      <article itemscope itemtype="https://schema.org/BlogPosting">
        <h1 class="entry-title" itemprop="headline">GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework</h1>

        <section itemprop="entry-text">
          <br>
          <p><a href="https://arxiv.org/pdf/2305.10841.pdf">paper</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/microsoft/muzic/tree/main/getmusic">code</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.reddit.com/r/MachineLearning/comments/13ol78c/r_getmusic_generating_any_music_tracks_with_a/">reddit</a></p>

          <h2 id="authors">Authors</h2>
          <ul>
            <li>Ang Lv (Renmin University of China) <a href="mailto:anglv@ruc.edu.cn">anglv@ruc.edu.cn</a></li>
            <li>Xu Tan^ (Microsoft Research Asia) <a href="mailto:xuta@microsoft.com">xuta@microsoft.com</a></li>
            <li>Peiling Lu (Microsoft Research Asia) <a href="mailto:peil@microsoft.com">peil@microsoft.com</a></li>
            <li>Wei Ye (Peking University) <a href="mailto:wye@pku.edu.cn">wye@pku.edu.cn</a></li>
            <li>Shikun Zhang (Peking University) <a href="mailto:zhangsk@pku.edu.cn">zhangsk@pku.edu.cn</a></li>
            <li>Jiang Bian (Microsoft Research Asia) <a href="mailto:jiabia@microsoft.com">jiabia@microsoft.com</a></li>
            <li>Rui Yan^ (Renmin University of China) <a href="mailto:ruiyan@ruc.edu.cn">ruiyan@ruc.edu.cn</a></li>
          </ul>
          <p><small>^ Corresponding author.</small></p>
          <h2 id="abstract">Abstract</h2>
          <p>Symbolic music generation aims to create musical notes, which can help users 
            compose music, such as generating target instrumental tracks from scratch, or
based on user-provided source tracks. Considering the diverse and flexible combination between source and target tracks, a unified model capable of generating
any arbitrary tracks is of crucial necessity. Previous works fail to address this
need due to inherent constraints in music representations and model architectures. To address this need, we propose a unified representation and diffusion
framework named GETMusic (‘GET’ stands for GEnerate music Tracks), which
includes a novel music representation named GETScore, and a diffusion model
named GETDiff. GETScore represents notes as tokens and organizes them in a
2D structure, with tracks stacked vertically and progressing horizontally over time.
During training, tracks are randomly selected as either the target or source. In
the forward process, target tracks are corrupted by masking their tokens, while
source tracks remain as ground truth. In the denoising process, GETDiff learns
to predict the masked target tokens, conditioning on the source tracks. With
separate tracks in GETScore and the non-autoregressive behavior of the model,
GETMusic can explicitly control the generation of any target tracks from scratch
or conditioning on source tracks. We conduct experiments on music generation
involving six instrumental tracks, resulting in a total of 665 combinations. GETMusic provides high-quality results across diverse combinations and surpasses
prior works proposed for some specific combinations. </p>
          

          <h2>Diverse Composition Tasks Showcasing</h2>
          <h3>1. Lead to Bass, Drum, Guitar, Piano, and String</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/ta-lc2bdgps.mp4" type="video/mp4">
          </video>
          
          <h3>2. Piano to Drum, Guitar, and String</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/pc2gsd.mp4" type="video/mp4">
          </video>

          <h3>3. Guitar to String</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/gc2bs.mp4" type="video/mp4">
          </video>
         
          <h3>4. Lead to Piano, String</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/heyjude-lc2ps.mp4" type="video/mp4">
          </video>

          <h3>5. Drum and Piano to Lead and String</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/dp2ls.mp4" type="video/mp4">
          </video>
          
          <h3>6. 6-Track Music Generation from Scratch</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/ug.mp4" type="video/mp4">
          </video>
          
          <h3>7. Infilling + Track-wise 1</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/pos1.mp4" type="video/mp4">
          </video>
          
          <h3>8. Infilling + Track-wise 2</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/pos2.mp4" type="video/mp4">
          </video>
          
          <h3>9. Bach Style Generation (Finetune on JSB Chorales dataset)</h3>
          <video width="90%" height="auto" controls >
            <source src="../audio/getmusic/video/bach.mp4" type="video/mp4">
          </video>

          <br /><br />
          <p>Thank you for watching &#128151;!</p>

        </section>
      </article>
    </main>

  </div>

  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-139981676-1', 'auto');
    ga('send', 'pageview');
  </script>

  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>



  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>




</body>

</html>
